{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1 style=\"margin-top:1em;font-weight:700\">ALGORITHM 1 (SPIKE SORTING)</h1>\n",
    "    <br>\n",
    "    <h3 style=\"margin-left:1em; margin-top:1em;font-weight:700\">NAVIGATION BUTTONS</h3>\n",
    "    <a href=\"#0\" style=\"text-decoration:none; color:#000000\">\n",
    "    <div style=\"padding:1em; height:12em; width:12em; border-radius:12em;  background-color:#EEEEEE;float:left;margin-left:1em;margin-top:1em\">\n",
    "        <center style=\"margin-top:1.2em; font-weight:700; font-size:2em; \">\n",
    "            0\n",
    "        </center>\n",
    "        <center style=\"font-weight:700; font-size:1em; \">\n",
    "            ALGORITHM SETTINGS\n",
    "        </center>\n",
    "    </div>\n",
    "    </a>\n",
    "    <a href=\"#1\" style=\"text-decoration:none; color:#000000\">\n",
    "    <div style=\"padding:1em; height:12em; width:12em; border-radius:12em;  background-color:#F0C38F;float:left;margin-left:1em;margin-top:1em\">\n",
    "        <center style=\"margin-top:1.2em; font-weight:700; font-size:2em; \">\n",
    "            1\n",
    "        </center>\n",
    "        <center style=\"font-weight:700; font-size:1em; \">\n",
    "            DATA READING AND NOISE FILTERING\n",
    "        </center>\n",
    "    </div>\n",
    "    </a>\n",
    "    <a href=\"#2\" style=\"text-decoration:none; color:#000000\">\n",
    "    <div style=\"padding:1em; height:12em; width:12em; border-radius:12em;  background-color:#EE999F; float:left; margin-left:1em; margin-top:1em\">\n",
    "        <center style=\"margin-top:1.2em; font-weight:700; font-size:2em;\">\n",
    "            2\n",
    "        </center>\n",
    "        <center style=\"font-weight:700; font-size:1em; \">\n",
    "            FILTERING\n",
    "        </center>    \n",
    "    </div>\n",
    "    </a>\n",
    "    <a href=\"#3\" style=\"text-decoration:none; color:#000000\">\n",
    "    <div style=\"padding:1em; height:12em; width:12em; border-radius:12em;  background-color:#AECDAD; float:left; margin-left:1em; margin-top:1em\">\n",
    "        <center style=\"margin-top:1.2em; font-weight:700; font-size:2em;\">\n",
    "            3\n",
    "        </center>\n",
    "        <center style=\"font-weight:700; font-size:1em; \">\n",
    "            THRESHOLDING AND SPIKE EXTRACTION\n",
    "        </center>\n",
    "    </div>\n",
    "    </a>\n",
    "    <a href=\"#4\" style=\"text-decoration:none; color:#000000\">\n",
    "    <div style=\"padding:1em; height:12em; width:12em; border-radius:12em;  background-color:#7EC0EE; float:left; margin-left:1em; margin-top:1em\">\n",
    "        <center style=\"margin-top:1.2em; font-weight:700; font-size:2em;\">\n",
    "            4\n",
    "        </center>\n",
    "        <center style=\"font-weight:700; font-size:1em; \">\n",
    "            FEATURE EXTRACTION (PCA)\n",
    "        </center>\n",
    "    </div>\n",
    "    </a>\n",
    "    <a href=\"#5\" style=\"text-decoration:none; color:#000000\">\n",
    "    <div style=\"padding:1em; height:12em; width:12em; border-radius:12em;  background-color:#E0BBE4; float:left; margin-left:1em; margin-top:1em\">\n",
    "        <center style=\"margin-top:1.2em; font-weight:700; font-size:2em;\">\n",
    "            5\n",
    "        </center>\n",
    "        <center style=\"font-weight:700; font-size:1em; \">\n",
    "            CLUSTERING\n",
    "        </center>\n",
    "    </div>\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "<a id='0'></a>\n",
    "<div style=\"background-color:#EEEEEE; font-size:1.5em;text-align:left;padding:0.7em;\"><b>0) ALGORITHM SETTINGS</b></div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Alg1 import *\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "pltstyle.use('seaborn-dark') #Comment this line if you want the white graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVING FILES OPTIONS\n",
    "<p>Set the corresponding \"save\" option to True or False to create a folder on the desktop and save all the pictures and data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images = False\n",
    "save_data = False\n",
    "\n",
    "# Do you want the folder name to contain the date of its creation? (It is useful if you run the code multiple times)\n",
    "time_name = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READING FILES OPTIONS\n",
    "<p>Set to True to read already created files. You have to set the directory of the files you want to read below in the code (see red checkpoints). <b>If it is the first time you run this algorithm set to False</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INPUT-OUTPUT FOLDERS NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Set here the input and output folder location:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the path to the file .h5 containing the signal\n",
    "input_path = \"\"\n",
    "\n",
    "#Set the name of the folder that will contain all the results\n",
    "MEA = \"\"\n",
    "cell_type = \"\"\n",
    "output_folder_name = \"Risultati \" + MEA + \" \" + cell_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (save_images == True) or (save_data == True):\n",
    "    if time_name == True: \n",
    "        now = str(datetime.datetime.now())[:19]\n",
    "        now = now.replace(\":\",\".\")\n",
    "        desktop = os.path.join(os.path.join(os.path.expanduser('~')), 'Desktop')\n",
    "        output_path = desktop + \"/\" + output_folder_name + \" \" + now\n",
    "        os.makedirs(output_path)\n",
    "        print(\"A new folder named\", output_folder_name + \" \" + now, \"that will contain all the results has been created on your desktop\")\n",
    "    else:\n",
    "        desktop = os.path.join(os.path.join(os.path.expanduser('~')), 'Desktop')\n",
    "        output_path = desktop + \"/\" + output_folder_name\n",
    "        os.makedirs(output_path)\n",
    "        print(\"\\nA new folder named '\" + output_folder_name + \"' has been created on your desktop\")\n",
    "else:\n",
    "    current_dir = None\n",
    "    \n",
    "if read_data == True:\n",
    "    desktop = os.path.join(os.path.join(os.path.expanduser('~')), 'Desktop')\n",
    "    output_path = desktop + \"/\" + output_folder_name\n",
    "    files_saved_path = output_path + \"/Files Saved\"\n",
    "    \n",
    "if save_data == True:\n",
    "    os.makedirs(files_saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br><br><br><br><br>\n",
    "<a id='1'></a>\n",
    "<div style=\"background-color:#F0C38F; font-size:1.5em;text-align:left;padding:0.7em\"><b>1) DATA READING + NOISE FILTERING</b></div> \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We plotted the useful information regarding the acquisition system (MEA) and we plotted a Power Spectral Density to see if there were any noise in the recordings. </p>\n",
    "\n",
    "- We found noises in all datasets at low frequencies and decided to filter those out using a bandpassfilter.\n",
    "\n",
    "- We also found some noise at certain frequencies (which depended on the dataset we were working with). Those frequencies were harmonics and we suppose that they were due to the acquisition system. We filtered them out using a notch filter.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA READING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_raw_data = RawData(input_path)\n",
    "duration = channel_raw_data.recordings[0].duration_time.magnitude / 1000000   # from microseconds to seconds\n",
    "timestamp = channel_raw_data.recordings[0].analog_streams[0].get_channel_sample_timestamps(0)[0]/1000000 # from microseconds to seconds\n",
    "fs = 1/(timestamp[-1]/timestamp.shape[0])\n",
    "\n",
    "print(\"\\n\\n\\033[1;31;47mMEA INFORMATIONS\\u001b[0m\")\n",
    "print(channel_raw_data.comment)\n",
    "print(channel_raw_data.date)\n",
    "print(channel_raw_data.clr_date)\n",
    "print(channel_raw_data.date_in_clr_ticks)\n",
    "print(channel_raw_data.file_guid)\n",
    "print(channel_raw_data.mea_name)\n",
    "print(channel_raw_data.mea_sn)\n",
    "print(channel_raw_data.mea_layout)\n",
    "print(channel_raw_data.program_name)\n",
    "print(channel_raw_data.program_version)\n",
    "print('Duration of the recording: ',round(duration,2),'seconds')\n",
    "print('Sampling Frequency: ',round(fs,2),'Hz')\n",
    "\n",
    "\n",
    "data = h5py.File(input_path,'r')\n",
    "data_readings = data['Data']['Recording_0']['AnalogStream']['Stream_0']['ChannelData'][()]\n",
    "info = data['Data']['Recording_0']['AnalogStream']['Stream_0']['InfoChannel'][()]\n",
    "info_table = pd.DataFrame(info, columns = list(info.dtype.fields.keys()))\n",
    "labels = info_table['Label']\n",
    "readings = pd.DataFrame(data = data_readings.transpose(), columns = labels)\n",
    "\n",
    "#Writing the info to a .txt file\n",
    "if save_data == True:\n",
    "    MEA_info = open(output_path + \"/MEA_info.txt\", \"w\")\n",
    "    info = \"MEA INFORMATION\" + \"\\n\" + \"Dataset: \" + input_path.split(\"/\")[-1] + \"\\n\" + \"Duration of the recording: \" + str(round(duration,2)) + ' seconds' + \"\\n\" + \"Sampling Frequency: \" + str(round(fs,2)) +' Hz'\n",
    "    MEA_info.write(info)\n",
    "    MEA_info.close()\n",
    "\n",
    "del data_readings, channel_raw_data, timestamp\n",
    "\n",
    "#Plotting the unfiltered signal present on one channel \n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(readings[b'47'],label=\"Segnale dall'elettrodo 47\", linewidth=1)\n",
    "plt.title(\"Segnale non filtrato da un elettrodo di esempio\")\n",
    "plt.ylabel('Segnale [\\u03BCV]')\n",
    "plt.xlabel('Campioni [0.1ms]')\n",
    "plt.grid()\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "#Saving image\n",
    "if (save_images == True):\n",
    "    file_name = output_path + \"/unfiltered_signal_example.png\"\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working Directory of the Preliminar Filtering\n",
    "if (save_images == True) or (save_data == True):\n",
    "    current_dir = output_path + \"/1. Data Reading and Preliminar Filtering\"\n",
    "    os.makedirs(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT UNFILTERED PSD\n",
    "\n",
    "colormap = cm.get_cmap('hsv')\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "\n",
    "\n",
    "#First Plot\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Spettro di potenza (PSD)')\n",
    "column = 0\n",
    "win_len = 1024*2\n",
    "overlap = 0.5*win_len\n",
    "for electrode in tqdm(readings.columns):\n",
    "    if electrode == b'Ref':\n",
    "        plt.psd(readings[electrode],1024 ,Fs=fs,window=np.hamming(1024),noverlap=50, label=str(electrode, 'utf-8'), color = \"#000000\", linewidth=0.7)\n",
    "    else:\n",
    "        plt.psd(readings[electrode],1024 ,Fs=fs,window=np.hamming(1024),noverlap=50, label=str(electrode, 'utf-8'), color = colormap(np.linspace(0, 1, 60))[column], linewidth=0.7)\n",
    "    plt.axis([0,5000,-20,52])\n",
    "    column +=1\n",
    "plt.legend(loc='upper right', ncol=8)\n",
    "plt.ylabel('Spettro di Potenza [dB/Hz]')\n",
    "plt.xlabel('Frequenza [Hz]')\n",
    "\n",
    "\n",
    "\n",
    "#Second Plot\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Spettro di potenza (PSD) - Zoom alle basse frequenze')\n",
    "column = 0\n",
    "win_len = 1024*16\n",
    "overlap = 0.5*win_len\n",
    "for electrode in tqdm(readings.columns):\n",
    "    if electrode == b'Ref':\n",
    "        plt.psd(readings[electrode], win_len ,Fs=fs,window=np.hamming(win_len), noverlap=overlap, label=str(electrode, 'utf-8'), color = \"#000000\", linewidth=0.7)\n",
    "    else:\n",
    "        plt.psd(readings[electrode], win_len ,Fs=fs,window=np.hamming(win_len),noverlap=overlap, label=str(electrode, 'utf-8'), color = colormap(np.linspace(0, 1, 60))[column], linewidth=0.7)\n",
    "    plt.axis([0,250,-20,52])\n",
    "    column +=1\n",
    "plt.legend(loc='upper right', ncol=8)\n",
    "plt.ylabel('Spettro di Potenza [dB/Hz]')\n",
    "plt.xlabel('Frequenza [Hz]')\n",
    "\n",
    "#Saving image\n",
    "if (save_images == True):\n",
    "    file_name =current_dir + \"/raw_psd.png\"\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FILTERING NOISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREFILTERING - LOW FREQUENCIES\n",
    "readings_rows = range(readings.shape[0])\n",
    "reading_columns = range(readings.shape[1])\n",
    "pre_filtered_readings = pd.DataFrame(data = 0, columns=readings.columns, index=readings_rows, dtype = \"float32\")\n",
    "\n",
    "b, a = scipy.signal.butter(N = 8, Wn=200, btype='highpass', analog=False, output='ba', fs=fs)\n",
    "for x in tqdm(range(readings.shape[1])):\n",
    "    pre_filtered_readings.values[:,x] = scipy.signal.filtfilt(b, a, readings.values[:,x])\n",
    "\n",
    "\n",
    "\n",
    "#Prefiltered plot - Low Frequencies removed\n",
    "colormap = cm.get_cmap('hsv')\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Spettro di potenza (rumore a bassa frequenza rimosso)')\n",
    "column = 0\n",
    "win_len = 1024*2\n",
    "overlap = 0.5*win_len\n",
    "for electrode in tqdm(readings.columns):\n",
    "    if electrode == b'Ref':\n",
    "        plt.psd(pre_filtered_readings[electrode], win_len,Fs=fs,window=np.hamming(win_len),noverlap=overlap, label=str(electrode, 'utf-8'), color = \"#000000\", linewidth=0.7)\n",
    "    else:\n",
    "        plt.psd(pre_filtered_readings[electrode], win_len,Fs=fs,window=np.hamming(win_len),noverlap=overlap, label=str(electrode, 'utf-8'), color = colormap(np.linspace(0, 1, 60))[column], linewidth=0.7)\n",
    "    plt.axis([0,5000,-20,52])\n",
    "    column +=1\n",
    "plt.ylabel('Spettro di Potenza [dB/Hz]')\n",
    "plt.xlabel('Frequenza')\n",
    "plt.legend(loc='upper right', ncol=8)\n",
    "\n",
    "\n",
    "\n",
    "#Second Plot \n",
    "win_len = 1024*16\n",
    "overlap = 0.5*win_len\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Spettro di potenza - Zoom alle basse frequenze (rumore a bassa frequenza rimosso)')\n",
    "column = 0\n",
    "for electrode in tqdm(readings.columns):\n",
    "    if electrode == b'Ref':\n",
    "        plt.psd(pre_filtered_readings[electrode], win_len,Fs=fs,window=np.hamming(win_len),noverlap=overlap, label=str(electrode, 'utf-8'), color = \"#000000\", linewidth=0.7)\n",
    "    else:\n",
    "        plt.psd(pre_filtered_readings[electrode], win_len,Fs=fs,window=np.hamming(win_len),noverlap=overlap, label=str(electrode, 'utf-8'), color = colormap(np.linspace(0, 1, 60))[column], linewidth=0.7)\n",
    "    plt.axis([0,250,-20,52])\n",
    "    column +=1\n",
    "plt.ylabel('Spettro di Potenza [dB/Hz]')\n",
    "plt.xlabel('Frequenza')\n",
    "plt.legend(loc='upper right', ncol=8)\n",
    "\n",
    "\n",
    "if (save_images == True):\n",
    "    file_name =current_dir + \"/freq_below_200_removed_psd.png\"\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREFILTERING - ADDITIONAL TWO PEAKS NOISES\n",
    "\n",
    "detect_band2 = False\n",
    "# True => calcola la seconda soglia indipendentemente dalla prima. Questo è utile se non si assume che il secondo rumore sia a frequenze multuiple del primo\n",
    "# False => calcola la seconda banda come multiplo della prima. Potrebbe in generale funzionare meglio, specialmente se il rumore al secondo picco è molto poco intenso\n",
    "\n",
    "percentage_increase_band1 = 0.3\n",
    "percentage_increase_band2 = 0.3\n",
    "#Le due percentuali di incremento delle bande da arrestare. Sono da scegliere in base ai grafici. \n",
    "#Se determinazione_banda_due è False, allora percentuale_incremento_2 non viene considerato\n",
    "\n",
    "samples_moving_avarage = 200\n",
    "#Determina lo \"smooth\" dei grafici della FFT. è utile se il rumore va su e giù rapidamente e rischia di superare la soglia in più punti\n",
    "\n",
    "multiple_threshold1 = 2\n",
    "multiple_threshold2 = 1.4\n",
    "#Determina la soglia come multiplo del valor medio del modulo della FFT. \n",
    "#Se determinazione_banda_2 è False allora multiplo_soglia_2 non viene considerato\n",
    "\n",
    "#Aggiungere second peak\n",
    "a_1, b_1, a_2, b_2, second_peak = detect_ref_noise(ref=pre_filtered_readings[b'Ref'].values, m1 = percentage_increase_band1, m2=percentage_increase_band2, multiple_first_peak=multiple_threshold1, multiple_second_peak=multiple_threshold2, current_dir=current_dir, fs=fs, detect_second_peak= detect_band2, n=samples_moving_avarage, save=save_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIRST PEAK DETECTED\n",
    "print(\"Filtering the first peak:\")\n",
    "time.sleep(0.3)\n",
    "for x in tqdm(range(readings.shape[1])):\n",
    "    pre_filtered_readings.values[:,x] = scipy.signal.filtfilt(b=b_1, a=a_1, x=pre_filtered_readings.values[:,x])\n",
    "\n",
    "#SECOND PEAK DETECTED (NOT ALWAYS PRESENT)  \n",
    "if (second_peak == True):\n",
    "    print(\"Filtering the second peak:\")\n",
    "    time.sleep(0.3)\n",
    "    for x in tqdm(range(readings.shape[1])):\n",
    "        pre_filtered_readings.values[:,x] = scipy.signal.filtfilt(b=b_2, a=a_2, x=pre_filtered_readings.values[:,x])\n",
    "\n",
    "print(\"Plotting the graph:\")\n",
    "#Prefiltered plot - All noise removed\n",
    "colormap = cm.get_cmap('hsv')\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Spettro di potenza (picchi di rumore rimossi)')\n",
    "column = 0\n",
    "win_len = 1024*2\n",
    "overlap = 0.5*win_len\n",
    "for electrode in tqdm(readings.columns):\n",
    "    if electrode == b'Ref':\n",
    "        plt.psd(pre_filtered_readings[electrode], win_len,Fs=fs,window=np.hamming(win_len),noverlap=overlap, label=str(electrode, 'utf-8'), color = \"#000000\", linewidth=0.7)\n",
    "    else:\n",
    "        plt.psd(pre_filtered_readings[electrode], win_len,Fs=fs,window=np.hamming(win_len),noverlap=overlap, label=str(electrode, 'utf-8'), color = colormap(np.linspace(0, 1, 60))[column], linewidth=0.7)\n",
    "    plt.axis([0,5000,-20,52])\n",
    "    column +=1\n",
    "\n",
    "plt.ylabel('Spettro di Potenza [db/Hz]')\n",
    "plt.xlabel('Frequenza')\n",
    "plt.legend(loc='upper right', ncol=8)\n",
    "\n",
    "if (save_images == True):\n",
    "    file_name = current_dir + \"/all_noise_removed_psd.png\"\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DIFFERENTIAL READING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Differential Reading\n",
    "for electrode in pre_filtered_readings.columns:\n",
    "    pre_filtered_readings[electrode] = pre_filtered_readings[electrode] - pre_filtered_readings[b'Ref']\n",
    "    \n",
    "pre_filtered_readings = pre_filtered_readings.drop([b'Ref'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "<a id='2'></a>\n",
    "<div style=\"background-color:#EE999F; font-size:1.5em;text-align:left;padding:0.7em\"><b>2) FILTERING + CORRELATION MATRIX</b></div> \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to see the frequencies that define an action potential of a neuron. So we can plot the time domain signal vs its Short Time Fourier Transform (STFT)\n",
    "<br>\n",
    "We found the typical frequencies of 300Hz 3000Hz cited in various papers well fit our data. \n",
    "<br>\n",
    "- Low frequencies are important for spike amplitude (especially for the slowest ones)\n",
    "- High frequencies are important for the morphology of the spikes\n",
    "\n",
    "<br>\n",
    "We then tried the following filters implemented using zero-phase filtering:\n",
    "\n",
    "1. FIR (Hamming window)\n",
    "2. FIR (Blackman-Nuttall window)\n",
    "3. IIR (Butterworth)\n",
    "\n",
    "We decided to filter the signal with the Butterworth one (due to maximal flatness) between 300Hz and 3000Hz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working Directory of the Filtering + Differential Reading + Correlation Matrix\n",
    "if (save_images == True) or (save_data == True):\n",
    "    current_dir = output_path + \"/2. Filtering\"\n",
    "    os.makedirs(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrode_example = b'36' #Change the name here to change the electrode\n",
    "\n",
    "t_initial = 20000 #Change the number here to select a different initial position\n",
    "lenght = 600 #Change the number here to enlarge or reduce the x axis (time)\n",
    "\n",
    "#Time domain signal\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(2, 1, 1)\n",
    "label = \"Channel \" + str(electrode_example, 'utf-8')\n",
    "plt.plot(pre_filtered_readings[electrode_example].values, label=label)\n",
    "plt.axis([t_initial,t_initial+lenght, -700, 400])\n",
    "plt.ylabel('Segnale [\\u03BCV]')\n",
    "plt.xlabel('Campioni')\n",
    "plt.grid()\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "\n",
    "#Short Time Fourier Transform\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.subplot(2, 1, 2)\n",
    "f, t, Sxx = scipy.signal.stft(x = pre_filtered_readings[electrode_example].values[t_initial:t_initial+lenght], fs=fs, window='boxcar', nperseg=2**6, noverlap=None, nfft=2**9)\n",
    "plt.pcolormesh(t*fs+t_initial, f, np.abs(Sxx))\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.ylabel('Frequenza [Hz]')\n",
    "plt.xlabel('Campioni')\n",
    "plt.axis\n",
    "plt.ylim([0,5000])\n",
    "\n",
    "#Saving images\n",
    "if (save_images == True):\n",
    "    file_name = current_dir + \"/freq_analysis_with_stft\" + \"_\" + str(electrode_example) + \".png\"\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "pltstyle.use('seaborn-dark') #Comment this line if you want the white graphs from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowcut = 300\n",
    "highcut = 3000\n",
    "\n",
    "readings_rows = range(pre_filtered_readings.shape[0])\n",
    "reading_columns = range(pre_filtered_readings.shape[1])\n",
    "filtered_readings = pd.DataFrame(data = 0, columns=pre_filtered_readings.columns, index=readings_rows, dtype = \"float32\")\n",
    "\n",
    "elab = pre_filtered_readings.values\n",
    "\n",
    "order=8\n",
    "for x in tqdm(range(filtered_readings.shape[1])):\n",
    "    filtered_readings.values[:,x] = butter_bandpass_filter(elab[:,x], lowcut, highcut, fs, order=order)\n",
    "\n",
    "del readings\n",
    "del pre_filtered_readings\n",
    "del elab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,9))\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "column = 0\n",
    "colormap = cm.get_cmap('hsv')\n",
    "for electrode in tqdm(filtered_readings.columns):\n",
    "    if electrode == b'Ref':\n",
    "        plt.psd(filtered_readings[electrode], win_len,Fs=fs,window=np.hamming(win_len),noverlap=overlap, label=str(electrode, 'utf-8'), color = \"#000000\")\n",
    "    else:\n",
    "        plt.psd(filtered_readings[electrode], win_len,Fs=fs,window=np.hamming(win_len),noverlap=overlap, label=str(electrode, 'utf-8'), color = colormap(np.linspace(0, 1, 60))[column])\n",
    "    plt.axis([0,5000,-25,35])\n",
    "    plt.title('Spettro di potenza')\n",
    "    column +=1\n",
    "plt.ylabel('Spettro di Potenza [dB/Hz]')\n",
    "plt.xlabel('Frequenza')\n",
    "\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "plt.legend(loc='upper right', ncol=10)\n",
    "\n",
    "if (save_images == True):\n",
    "    file_name = current_dir + \"/filtered_psd.png\"\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CORRELATION MATRIX AND DELETION OF HIGH CORRELATED CHANNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = filtered_readings.iloc[:1000000,:].corr()\n",
    "plt.figure(figsize=(30,30))\n",
    "sns.heatmap(corr_matrix, annot=False, yticklabels = True)\n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "if (save_images == True):\n",
    "    file_name = current_dir + \"/correlation_matrix_before.png\"\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_corr = 0.85\n",
    "\n",
    "correlated_channels = set()\n",
    "\n",
    "for column in corr_matrix.columns:\n",
    "    for row in corr_matrix.index:\n",
    "        if row != column and corr_matrix[row][column] > max_corr:\n",
    "            correlated_channels.add(row)\n",
    "\n",
    "print(\"\\nThe following\", len(correlated_channels),\"channels are correlated: \", correlated_channels,\"\\nWith a correlation over:\", max_corr*100, \"%\\n\")\n",
    "\n",
    "absolute_mean = dict()\n",
    "for electrode in correlated_channels:\n",
    "    absolute_mean[electrode] = np.mean(abs(filtered_readings[electrode].values))\n",
    "    \n",
    "#Keeping only the channel that has maximum absolute value\n",
    "maximum_value = float(0)\n",
    "maximum_name = \"\"\n",
    "for electrode in absolute_mean:\n",
    "    if absolute_mean[electrode] > maximum_value:\n",
    "        maximum_value = absolute_mean[electrode]\n",
    "        maximum_name = electrode\n",
    "\n",
    "correlated_channels.remove(maximum_name)\n",
    "\n",
    "#Deleting all the other channels from the correlation matrix\n",
    "corr_matrix = corr_matrix.drop(labels = correlated_channels, axis=0)\n",
    "corr_matrix = corr_matrix.drop(labels = correlated_channels, axis=1)\n",
    "\n",
    "#Deleting all the other channels from the filtered readings\n",
    "filtered_readings = filtered_readings.drop(columns = correlated_channels)\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "sns.heatmap(corr_matrix, annot=False, yticklabels = True)\n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "if (save_images == True):\n",
    "    file_name = current_dir + \"/correlation_matrix_after.png\"\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br><br><br><br><br>\n",
    "<a id='3'></a>\n",
    "<div style=\"background-color:#AECDAD; font-size:1.5em;text-align:left;padding:0.7em\"><b>3) THRESHOLDING + SPIKE EXTRACTION</b></div> \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We tried two ways of calculating the threshold:</p>\n",
    "\n",
    "1. Standard Deviation (SD)\n",
    "2. Median Absolute Deviation (MAD)\n",
    "\n",
    "<p>We opted for the estimator which better identified the noise variance, which is the MAD. The Median Absolute Deviation is indeed less sensible to the presence of outliers (i.e. spikes) and this is useful as we need to estimate only the background noise amplitude (without the presence of spikes). The real threshold is then a multiple of the chosen estimator.</p>\n",
    "<p>We then extracted the signal which exceeded the threshold which is presumably the spikes<br>\n",
    "At the end of this section there is a function that allows us to see the number of spikes detected as a function of the multiple of the chosen threshold</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working Directory of the Thresholding + Spike Extraction\n",
    "if (save_images == True) or (save_data == True):\n",
    "    current_dir = output_path + \"/3. Thresholding + Spike Extraction\"\n",
    "    os.makedirs(current_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can choose \"MAD\" and \"STD\"\n",
    "threshold_method = \"MAD\"\n",
    "\n",
    "#Multiple\n",
    "n = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if threshold_method == \"MAD\":\n",
    "    deviation_list = pd.DataFrame(data = 0, columns=filtered_readings.columns, index=range(1))\n",
    "    threshold = pd.DataFrame(data = 0, columns=filtered_readings.columns, index = range(1))\n",
    "    for electrode in tqdm(filtered_readings.columns):\n",
    "        deviation_list[electrode] = scipy.stats.median_absolute_deviation(filtered_readings[electrode].values)\n",
    "        threshold[electrode] = (deviation_list[electrode])*n\n",
    "    \n",
    "elif threshold_method == \"STD\":\n",
    "    deviation_list = pd.DataFrame(data = 0, columns=filtered_readings.columns, index=range(1))\n",
    "    threshold = pd.DataFrame(data = 0, columns=filtered_readings.columns, index = range(1))\n",
    "    for electrode in tqdm(filtered_readings.columns):\n",
    "        deviation_list[electrode] = np.std(filtered_readings[electrode].values)\n",
    "        threshold[electrode] = (np.std(filtered_readings[electrode].values))*n\n",
    "        \n",
    "else:\n",
    "    raise Exception(\"The variable named 'threshold_method' must be either 'MAD' or 'STD'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SPIKE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_readings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = pd.DataFrame(data = 0, columns=filtered_readings.columns, index=[\"corresponding number\"])\n",
    "crossings = []\n",
    "crosscorr_indexes = []\n",
    "indexes = []\n",
    "extracted = []\n",
    "\n",
    "\n",
    "electrode_list = filtered_readings.columns\n",
    "    \n",
    "i = 0\n",
    "for electrode in tqdm(filtered_readings.columns):\n",
    "\n",
    "\n",
    "    legend[electrode] = i\n",
    "    sgn = filtered_readings[electrode].values\n",
    "    thr = float(threshold[electrode].values[0])\n",
    "\n",
    "    #Detect crossing of the threshold\n",
    "    crossings.append(DetectCrossings(signal = sgn, threshold = thr, fs = fs))\n",
    "    \n",
    "    print(\"Il canale \" + str(electrode) + \" ha: \" + str(len(crossings[i])) + \" spike\")\n",
    "    \n",
    "    #Align the spikes to crosscorrelation\n",
    "    crosscorr_indexes.append(AlignToCrosscorrelation(signal = sgn, given_indexes = np.array(crossings[i], dtype=int), fs = fs))\n",
    "    \n",
    "    #Extract the spikes and their indexes\n",
    "    spks, idx = ExtractWaveform(signal = sgn, indexes = np.array(crosscorr_indexes[i], dtype=int), fs = fs)\n",
    "    #Save the spikes\n",
    "    extracted.append(spks)\n",
    "    #Save their indexes\n",
    "    indexes.append(idx)\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "del crossings, crosscorr_indexes, spks, idx, sgn, thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of spikes detected as a function of the multiple of the threshold\n",
    "\n",
    "ThresholdVariation(filtered_readings=filtered_readings, save=save_images, current_dir=current_dir, aligned_indexes=indexes, deviation_list=deviation_list, fs=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br><br><hr>\n",
    "<h3 style=\"color:red\">CHECKPOINT</h3>\n",
    "\n",
    "<h4 style=\"color:black\">Saving Waveforms</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data == True:  \n",
    "    file_name = files_saved_path + \"/ExtractedWaveforms.h5\"\n",
    "    print(\"Saving path: \" + file_name)\n",
    "    \n",
    "    decoded_electrode_list = []\n",
    "    for electrode in electrode_list:\n",
    "        decoded_electrode_list.append(int(electrode.decode()))\n",
    "        \n",
    "    keys = np.array(range(len(extracted)))\n",
    "\n",
    "    hf = h5py.File(file_name, 'w')\n",
    "    \n",
    "    hf.create_dataset(\"electrode_list\", data=decoded_electrode_list)\n",
    "    hf.create_dataset(\"keys\", data=keys)\n",
    "    for i in range(len(extracted)):\n",
    "        data_to_save = extracted[i]\n",
    "        data_name = str(i)\n",
    "        hf.create_dataset(data_name, data=data_to_save)\n",
    "        \n",
    "    hf.close()\n",
    "    \n",
    "    print(\"Waveforms saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:black\">Saving Indexes</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data == True:  \n",
    "    file_name = files_saved_path + \"/ExtractedIndexes.h5\"\n",
    "    print(\"Saving path: \" + file_name)\n",
    "    \n",
    "    decoded_electrode_list = []\n",
    "    for electrode in electrode_list:\n",
    "        decoded_electrode_list.append(int(electrode.decode()))\n",
    "        \n",
    "    keys = np.array(range(len(indexes)))\n",
    "\n",
    "    hf = h5py.File(file_name, 'w')\n",
    "    \n",
    "    hf.create_dataset(\"electrode_list\", data=decoded_electrode_list)\n",
    "    hf.create_dataset(\"keys\", data=keys)\n",
    "    for i in range(len(indexes)):\n",
    "        data_to_save = indexes[i]\n",
    "        data_name = str(i)\n",
    "        hf.create_dataset(data_name, data=data_to_save)\n",
    "        \n",
    "    hf.close()\n",
    "    \n",
    "    print(\"Indexes saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:black\">Saving Legend</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (save_data == True):\n",
    "    \n",
    "    #Decoding from bytes to str\n",
    "    decoded_electrodes = []\n",
    "    for electrode in legend.columns:\n",
    "        decoded_electrodes.append(electrode.decode())\n",
    "\n",
    "    legend.columns = decoded_electrodes\n",
    "    del decoded_electrodes\n",
    "    \n",
    "    file_name = files_saved_path + \"/legend.h5\"\n",
    "    legend.to_hdf(file_name, key='data', mode='w')\n",
    "    \n",
    "    #Re-Encoding from str to bytes\n",
    "    encoded_electrodes = []\n",
    "    for electrode in legend.columns:\n",
    "        encoded_electrodes.append(electrode.encode(encoding='utf-8'))\n",
    "        \n",
    "    legend.columns = encoded_electrodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:black\">Saving (Sampling Frequency) and (Number of Samples)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data == True:\n",
    "    time_vector = [fs, filtered_readings.shape[0]]\n",
    "    file_name = files_saved_path + \"/time_vector\"\n",
    "    np.savez(file_name, time_vector)\n",
    "    print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<h4 style=\"color:black\">Loading Waveforms</h4>\n",
    "<p>You have to add the path to the file containing ExtractedWaveforms.h5 of the correct dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_saved_path = \"/Users/lucasubitoni/OneDrive - Politecnico di Milano/3° Anno/2° Semestre/Progetto/Tesi scritta/Risultati Algoritmo 1/Risultati MIP 4 LRKK2/Files Saved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_data == True:\n",
    "    extracted = []\n",
    "    \n",
    "    file_name = files_saved_path + \"/ExtractedWaveforms.h5\"\n",
    "    print(\"Loading path: \" + file_name)\n",
    "    hf = h5py.File(file_name, 'r')\n",
    "    \n",
    "    electrode_list = []\n",
    "    for electrode in np.array(hf.get(\"electrode_list\")):\n",
    "        electrode_list.append(str(electrode).encode(encoding='utf-8'))\n",
    "    \n",
    "    for i in np.array(hf.get(\"keys\")):\n",
    "        data_i = hf.get(str(i))\n",
    "        data_i = np.array(data_i)\n",
    "        extracted.append(data_i)\n",
    "\n",
    "    print(\"Waveforms loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:black\">Loading Indexes</h4>\n",
    "<p>You have to add the path to the file containing ExtractedIndexes.h5 of the correct dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_data == True:\n",
    "    indexes = []\n",
    "    \n",
    "    file_name = files_saved_path + \"/ExtractedIndexes.h5\"\n",
    "    print(\"Loading path: \" + file_name)\n",
    "    hf = h5py.File(file_name, 'r')\n",
    "    \n",
    "    electrode_list = []\n",
    "    for electrode in np.array(hf.get(\"electrode_list\")):\n",
    "        electrode_list.append(str(electrode).encode(encoding='utf-8'))\n",
    "    \n",
    "    for i in np.array(hf.get(\"keys\")):\n",
    "        data_i = hf.get(str(i))\n",
    "        data_i = np.array(data_i)\n",
    "        indexes.append(data_i)\n",
    "\n",
    "    print(\"Indexes loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:black\">Loading Legend</h4>\n",
    "<p>You have to add the path to the file containing Legend.h5 of the correct dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (read_data == True):\n",
    "    file_name = files_saved_path + \"/legend.h5\"\n",
    "    print(\"Loading path: \" + file_name)\n",
    "    legend = pd.read_hdf(file_name, 'data')\n",
    "    \n",
    "    #Encoding from str to bytes\n",
    "    encoded_electrodes = []\n",
    "    for electrode in legend.columns:\n",
    "        encoded_electrodes.append(electrode.encode(encoding='utf-8'))\n",
    "\n",
    "    legend.columns = encoded_electrodes\n",
    "    del encoded_electrodes\n",
    "    \n",
    "print(\"Legend loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br><br><br><br><br>\n",
    "<a id='4'></a>\n",
    "<div style=\"background-color:#7EC0EE; font-size:1.5em;text-align:left;padding:0.7em\"><b>4) EXTRACT SPIKE CHARACTERISTICS (PCA)</b></div> \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used Principal Component Analysis (PCA) to find the 3 most important characteristics that defined the spikes detected by a single electrode. We investigated two main ways of detecting and extracting those characteristics:\n",
    "1. Morphologic characteristics: independent on the previous alignment method; the spike has to be cut entirely but not perfectely aligned with others. (those characteristics are maximum/minimum voltage, the maxiumum/minimum derivative and so on...) \n",
    "2. Voltage dependent characteristics: dependent on the previous alignment method; the characteristics are the voltages at each point\n",
    "\n",
    "We chose to use the voltage dependent characteristics as the crosscorrelation algorithm is quite robust\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working Directory of the Extract Characteristics\n",
    "if (save_images == True) or (save_data == True):\n",
    "    current_dir = output_path + \"/4. PCA\"\n",
    "    os.makedirs(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf() #To clear the cache of matplotlib\n",
    "principal_components = []\n",
    "\n",
    "for electrode in electrode_list:\n",
    "    print(\"\\n\\nELECTRODE: \", electrode)\n",
    "    principal_components.append(PerformPCA(x=extracted[legend[electrode].values[0]], current_dir=current_dir, electrode_name=electrode, n=3, show=True, save=save_images))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br><br><br><br><br>\n",
    "<a id='5'></a>\n",
    "<div style=\"background-color:#E0BBE4; font-size:1.5em;text-align:left;padding:0.7em\"><b>5) CLUSTERING</b></div> \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried three main ways of clustering neurons together.\n",
    "1. DBSCAN\n",
    "2. KMEANS\n",
    "3. HIERARCHICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working Directory of the Clustering\n",
    "if (save_images == True) or (save_data == True):\n",
    "    current_dir = output_path + \"/5. Clustering\"\n",
    "    os.makedirs(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can choose between \"DBSCAN\" and \"KMEANS\" and \"HIERARCHICAL\" or \"ALL\" to run them all and compare the outputs\n",
    "\n",
    "clustering_method = \"HIERARCHICAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf() #To clear the cache of matplotlib\n",
    "points = len(extracted[0][0])\n",
    "\n",
    "# DBSCAN===============================================================================================\n",
    "if (clustering_method == \"DBSCAN\") or (clustering_method == \"ALL\"):\n",
    "    \n",
    "    #Directory of the DBSCAN\n",
    "    if (save_images == True) or (save_data == True):\n",
    "        DBSCAN_dir = current_dir + \"/DBSCAN\"\n",
    "        os.makedirs(DBSCAN_dir)\n",
    "    else:\n",
    "        DBSCAN_dir = None\n",
    "\n",
    "    DBSCAN_cluster = []\n",
    "    for electrode in tqdm(electrode_list):\n",
    "        print(\"\\n\\nELECTRODE: \",electrode)\n",
    "        DBSCAN_cluster.append(perform_pca_DBSCAN(extracted[legend[electrode].values[0]],np.array(indexes[legend[electrode].values[0]]),\n",
    "                                      fs = fs,n_comp=3, current_dir = DBSCAN_dir, electrode=electrode,points=points, distanza = 1, punti_min = 50, save=save_images, ignorare = 500))\n",
    "\n",
    "    #Removal of possible empty clusters\n",
    "    for i, electrode in enumerate(DBSCAN_cluster):\n",
    "        if electrode == []:\n",
    "            DBSCAN_cluster[i] = None\n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "# KMEANS===============================================================================================\n",
    "elif (clustering_method == \"KMEANS\") or (clustering_method == \"ALL\"):\n",
    "    \n",
    "    #Directory of the HIERARCHICAL\n",
    "    if (save_images == True) or (save_data == True):\n",
    "        KMEANS_dir = current_dir + \"/KMEANS\"\n",
    "        os.makedirs(KMEANS_dir)\n",
    "    else:\n",
    "        KMEANS_dir = None\n",
    "\n",
    "    KMEANS_cluster = []\n",
    "    for electrode in tqdm(electrode_list):\n",
    "        print(\"\\n\\nELECTRODE: \",electrode)\n",
    "        KMEANS_cluster.append(perform_pca_KMEANS(cutouts=extracted[legend[electrode].values[0]], spike_list=np.array(indexes[legend[electrode].values[0]]), points=points, fs=fs, n_comp=3, electrode=electrode, current_dir=KMEANS_dir,  min_silhouette_score=0.275, ignorare=500, centroids=False, save=False))\n",
    "\n",
    "    #Removal of possible empty clusters\n",
    "    for i, electrode in enumerate(KMEANS_cluster):\n",
    "        if electrode == []:\n",
    "            KMEANS_cluster[i] = None\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "# HIERARCHICAL=========================================================================================\n",
    "elif (clustering_method == \"HIERARCHICAL\") or (clustering_method == \"ALL\"):\n",
    "    \n",
    "    #Directory of the HIERARCHICAL\n",
    "    if (save_images == True) or (save_data == True):\n",
    "        HIERARCHICAL_dir = current_dir + \"/HIERARCHICAL\"\n",
    "        os.makedirs(HIERARCHICAL_dir)\n",
    "    else:\n",
    "        HIERARCHICAL_dir = None\n",
    "\n",
    "    HIERARCHICAL_cluster = []\n",
    "    for electrode in tqdm(electrode_list):\n",
    "        print(\"\\n\\nELECTRODE: \",electrode)\n",
    "        HIERARCHICAL_cluster.append(perform_pca_HIERARCHICAL(cutouts=extracted[legend[electrode].values[0]], spike_list=np.array(indexes[legend[electrode].values[0]]), points=points, fs=fs, n_comp=3, electrode=electrode, current_dir=HIERARCHICAL_dir, min_silhouette_score=0.275, ignorare=500, centroids=False, save=save_images))\n",
    "\n",
    "    #Removal of possible empty clusters\n",
    "    for i, electrode in enumerate(HIERARCHICAL_cluster):\n",
    "        if electrode == []:\n",
    "            HIERARCHICAL_cluster[i] = None\n",
    "            \n",
    "    \n",
    "\n",
    "            \n",
    "#______________________________________________________________________________________________________EXCEPTION\n",
    "else:\n",
    "    raise Exception(\"The options are 'DBSCAN', 'KMEANS', 'HIERARCHICAL' or alternatively you can run them all by using the word 'ALL'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<h3 style=\"color:black\">SAVING CLUSTERED INDEXES</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data == True: \n",
    "\n",
    "    if (clustering_method == \"DBSCAN\") or (clustering_method == \"ALL\"):\n",
    "        file_name = files_saved_path + \"/NeuronIndexesDBSCAN\"\n",
    "        np.savez(file_name, DBSCAN_cluster)\n",
    "        print(\"DBSCAN clustered indexes saved!\")\n",
    "        \n",
    "    elif (clustering_method == \"KMEANS\") or (clustering_method == \"ALL\"):\n",
    "        file_name = files_saved_path + \"/NeuronIndexesKMEANS\"\n",
    "        np.savez(file_name, KMEANS_cluster)\n",
    "        print(\"KMEANS clustered indexes saved!\")\n",
    "        \n",
    "    elif (clustering_method == \"HIERARCHICAL\") or (clustering_method == \"ALL\"):\n",
    "        file_name = files_saved_path + \"/NeuronIndexesHIERARCHICAL\"\n",
    "        np.savez(file_name, HIERARCHICAL_cluster)\n",
    "        print(\"HIERARCHICAL clustered indexes saved!\")\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"The options are 'DBSCAN', 'KMEANS', 'HIERARCHICAL' or alternatively you can run them all by using the word 'ALL'\")\n",
    "        \n",
    "print(\"Algorithm 1 ENDED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXTRA (PLOT A SPECIFIC CHANNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "#Use this cell of code to plot the spikes detected by a specific channel\n",
    "\n",
    "electrode_example = b'36' #Change the name here to change electrode\n",
    "\n",
    "spike_count = 1 #Change the number here to increase or decrase the spikes to draw. \n",
    "                    #To see all spikes use: len(extracted[legend[electrode_example].values[0]])\n",
    "\n",
    "#_________________________________________________________________________________________________________\n",
    "\n",
    "if len(extracted[legend[electrode_example].values[0]]) < spike_count:\n",
    "    spike_count = len(extracted[legend[electrode_example].values[0]])\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "plt.xlabel('Tempo [0.1ms]')\n",
    "plt.ylabel('Tensione [\\u03BCV]')\n",
    "i=0\n",
    "while (i<spike_count):\n",
    "    plt.plot(extracted[legend[electrode_example].values[0]][i+428], color=\"#000000\", alpha=0.3)\n",
    "    i += 1\n",
    "plt.axhline(threshold[electrode_example].values, 0,1, color=\"#FF0000\")\n",
    "plt.axhline(-threshold[electrode_example].values, 0,1, color=\"#FF0000\")\n",
    "title = str(\"First \") + str(i) + str(\" spike aligned and extracted from electrode \") + str(electrode_example)\n",
    "#plt.title(title)\n",
    "plt.grid()\n",
    "\n",
    "if (save_images == True):\n",
    "    file_name = current_dir + \"/spike_from_\" + str(electrode_example) + \".png\"\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXTRA SEE THE EFFECT OF THE BURSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_in = 74884\n",
    "value_fin = 83836\n",
    "\n",
    "#Plotting the filtered signal present on one channel to find bursts\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "plt.plot(filtered_readings[b'37'], linewidth=1.5, label=\"Canale 37 MIP4\")\n",
    "plt.ylabel('Segnale [\\u03BCV]')\n",
    "plt.xlabel('Campioni [0.1ms]')\n",
    "plt.grid(lw=2)\n",
    "plt.axis([value_in-7000, value_fin+7000, -4000, 6000])\n",
    "plt.axvline(value_in, color=\"red\", alpha=0.3, lw=2)\n",
    "plt.axvline(value_fin, color=\"red\", alpha=0.3, lw=2)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_in = 80000\n",
    "value_fin = 84000\n",
    "\n",
    "#Plotting the filtered signal present on one channel to find bursts\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "plt.plot(filtered_readings[b'37'], linewidth=1.5, label=\"Canale 37 MIP4\")\n",
    "plt.ylabel('Segnale [\\u03BCV]')\n",
    "plt.xlabel('Campioni [0.1ms]')\n",
    "plt.grid(lw=2)\n",
    "plt.axis([value_in-45000, value_fin+55000, -4000, 6000])\n",
    "#plt.axvline(value_in, color=\"red\", alpha=0.3, lw=2)\n",
    "#plt.axvline(value_fin, color=\"red\", alpha=0.3, lw=2)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
